{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Facial Emotion Recognition</center>","metadata":{}},{"cell_type":"markdown","source":"## Introduction\nFacial emotion recognition using Convolutional Neural Networks (CNN) is a technique to  recognize human emotions from facial expressions in images.<br>\nThe objective of this project is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). \n### Approach\n<li>A CNN model is trained on the FER dataset to learn the features of facial expressions that are associated with each emotion. \n<li>The model uses convolutional layers to extract features from the input images and pooling layers to reduce the dimensionality of the feature maps. \n<li>The extracted features are then fed into fully connected layers to classify the emotion.","metadata":{}},{"cell_type":"markdown","source":"## Dataset Description\n<li>The dataset consists of a collection of grayscale images (48x48 pixel) of human faces, where each image is labeled with one of seven basic emotions: \nanger, disgust, fear, happiness, sadness, surprise, or neutral.<br>\n<li>The training set consists of 28,709 examples.<br>\n<li>The test set consists of over 7,000 samples","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nfrom tqdm.notebook import tqdm\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.259704Z","iopub.execute_input":"2023-03-23T05:25:22.260304Z","iopub.status.idle":"2023-03-23T05:25:22.268535Z","shell.execute_reply.started":"2023-03-23T05:25:22.260264Z","shell.execute_reply":"2023-03-23T05:25:22.267515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Dataset","metadata":{}},{"cell_type":"code","source":"train_dir = \"/kaggle/input/fer2013/train\"  # train data folder\ntest_dir = \"/kaggle/input/fer2013/test\"    # test data folder","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.275559Z","iopub.execute_input":"2023-03-23T05:25:22.278160Z","iopub.status.idle":"2023-03-23T05:25:22.283117Z","shell.execute_reply.started":"2023-03-23T05:25:22.278131Z","shell.execute_reply":"2023-03-23T05:25:22.282145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a function to do the following\n<li> It takes in the folder name as input and loads all the images in that folder along with their corresponding labels. \n<li>It then loops through all the subfolders (labels) in the given folder and then loops through all the files (images) in each subfolder.\n<li>For each image file, it constructs the full path of the image using and appends it to the `image_paths` list. The corresponding label is also appended to the `labels` list.\n<li>Finally, the function returns the two lists.","metadata":{}},{"cell_type":"code","source":"def load_dataset(directory):\n    image_paths = []\n    labels = []\n    \n    for label in os.listdir(directory):\n      \n        for filename in os.listdir(directory+\"/\"+label):\n            image_path = os.path.join(directory, label, filename)\n            image_paths.append(image_path)\n            labels.append(label)\n\n    return image_paths, labels","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.286978Z","iopub.execute_input":"2023-03-23T05:25:22.287304Z","iopub.status.idle":"2023-03-23T05:25:22.293699Z","shell.execute_reply.started":"2023-03-23T05:25:22.287276Z","shell.execute_reply":"2023-03-23T05:25:22.292395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## convert into dataframe\ntrain = pd.DataFrame()\ntrain['image'], train['label'] = load_dataset(train_dir)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.298029Z","iopub.execute_input":"2023-03-23T05:25:22.298433Z","iopub.status.idle":"2023-03-23T05:25:22.395072Z","shell.execute_reply.started":"2023-03-23T05:25:22.298352Z","shell.execute_reply":"2023-03-23T05:25:22.393765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.396952Z","iopub.execute_input":"2023-03-23T05:25:22.401895Z","iopub.status.idle":"2023-03-23T05:25:22.411556Z","shell.execute_reply.started":"2023-03-23T05:25:22.401855Z","shell.execute_reply":"2023-03-23T05:25:22.410532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.412995Z","iopub.execute_input":"2023-03-23T05:25:22.413428Z","iopub.status.idle":"2023-03-23T05:25:22.427714Z","shell.execute_reply.started":"2023-03-23T05:25:22.413390Z","shell.execute_reply":"2023-03-23T05:25:22.426623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.429941Z","iopub.execute_input":"2023-03-23T05:25:22.430246Z","iopub.status.idle":"2023-03-23T05:25:22.443999Z","shell.execute_reply.started":"2023-03-23T05:25:22.430207Z","shell.execute_reply":"2023-03-23T05:25:22.442728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Similarly, construct a dataframe for Test data","metadata":{}},{"cell_type":"code","source":"test = pd.DataFrame()\ntest['image'], test['label'] = load_dataset(test_dir)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.446913Z","iopub.execute_input":"2023-03-23T05:25:22.447512Z","iopub.status.idle":"2023-03-23T05:25:22.480473Z","shell.execute_reply.started":"2023-03-23T05:25:22.447475Z","shell.execute_reply":"2023-03-23T05:25:22.479640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.483435Z","iopub.execute_input":"2023-03-23T05:25:22.483712Z","iopub.status.idle":"2023-03-23T05:25:22.490046Z","shell.execute_reply.started":"2023-03-23T05:25:22.483686Z","shell.execute_reply":"2023-03-23T05:25:22.488993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.491485Z","iopub.execute_input":"2023-03-23T05:25:22.492142Z","iopub.status.idle":"2023-03-23T05:25:22.503138Z","shell.execute_reply.started":"2023-03-23T05:25:22.492107Z","shell.execute_reply":"2023-03-23T05:25:22.502134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Let's load an image file using the <b>Python Imaging Library (Pillow) </b>and display it using Matplotlib.","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n# Load image using Pillow\nimg = Image.open(train['image'][0])\nplt.imshow(img, cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.504522Z","iopub.execute_input":"2023-03-23T05:25:22.507478Z","iopub.status.idle":"2023-03-23T05:25:22.725649Z","shell.execute_reply.started":"2023-03-23T05:25:22.507441Z","shell.execute_reply":"2023-03-23T05:25:22.724611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.727470Z","iopub.execute_input":"2023-03-23T05:25:22.727867Z","iopub.status.idle":"2023-03-23T05:25:22.735925Z","shell.execute_reply.started":"2023-03-23T05:25:22.727828Z","shell.execute_reply":"2023-03-23T05:25:22.734737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check the Image size\n<li> `size` attribute returns a tuple of the width and height of the image in pixels.\n<li><b>'img.getbands()'</b> method returns a tuple of the band names in the image. <br>\n    For example, an RGB image has three bands: red, green, and blue.<br>\n    If the image is grayscale, getbands method of the image object will return a tuple containing a single string element \"L\". \"L\" stands for \"Luminance\", which is the intensity of the pixel's brightness.\n\n","metadata":{}},{"cell_type":"code","source":"shape = img.size + img.getbands() \nprint(\"The shape of the image is:\", shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.737678Z","iopub.execute_input":"2023-03-23T05:25:22.738504Z","iopub.status.idle":"2023-03-23T05:25:22.745490Z","shell.execute_reply.started":"2023-03-23T05:25:22.738467Z","shell.execute_reply":"2023-03-23T05:25:22.744140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resizing(images):\n    features = []\n    for image in tqdm(images):\n        img = Image.open(image)\n        img = np.array(img)\n        features.append(img)\n    features = np.array(features)\n    features = features.reshape(len(features), 48, 48, 1)\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.747043Z","iopub.execute_input":"2023-03-23T05:25:22.748147Z","iopub.status.idle":"2023-03-23T05:25:22.754499Z","shell.execute_reply.started":"2023-03-23T05:25:22.748112Z","shell.execute_reply":"2023-03-23T05:25:22.753627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li>The above function takes a list of image paths as input, opens each image using the PIL Image module, converts it into a numpy array and appends it to a list called features. \n<li>The `tqdm()` function is used to display a progress bar during the loop execution.\n<li>After processing all images in the input list, the features list is converted into a numpy array and reshaped into a four-dimensional array with dimensions <b>(number of samples, height, width, channels)</b>, \n<li>Each image is resized to a square image with dimensions 48x48 and a single color channel, which is suitable for inputting into a neural network.   ","metadata":{}},{"cell_type":"code","source":"train_features = resizing(train['image'])","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:25:22.756080Z","iopub.execute_input":"2023-03-23T05:25:22.756853Z","iopub.status.idle":"2023-03-23T05:26:05.511716Z","shell.execute_reply.started":"2023-03-23T05:25:22.756819Z","shell.execute_reply":"2023-03-23T05:26:05.510642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:05.513156Z","iopub.execute_input":"2023-03-23T05:26:05.514171Z","iopub.status.idle":"2023-03-23T05:26:05.522396Z","shell.execute_reply.started":"2023-03-23T05:26:05.514128Z","shell.execute_reply":"2023-03-23T05:26:05.521275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = resizing(test['image'])","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:05.527239Z","iopub.execute_input":"2023-03-23T05:26:05.527870Z","iopub.status.idle":"2023-03-23T05:26:16.262503Z","shell.execute_reply.started":"2023-03-23T05:26:05.527828Z","shell.execute_reply":"2023-03-23T05:26:16.261431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.264049Z","iopub.execute_input":"2023-03-23T05:26:16.264472Z","iopub.status.idle":"2023-03-23T05:26:16.271540Z","shell.execute_reply.started":"2023-03-23T05:26:16.264429Z","shell.execute_reply":"2023-03-23T05:26:16.270524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## normalize the image\nx_train = train_features/255\nx_test = test_features/255","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.273100Z","iopub.execute_input":"2023-03-23T05:26:16.273747Z","iopub.status.idle":"2023-03-23T05:26:16.491746Z","shell.execute_reply.started":"2023-03-23T05:26:16.273697Z","shell.execute_reply":"2023-03-23T05:26:16.490429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Encoding the output column (label)\n\nfrom sklearn.preprocessing import LabelEncoder\nla = LabelEncoder()\nla.fit(train['label'])\ny_train = la.transform(train['label'])\ny_test = la.transform(test['label'])","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.493496Z","iopub.execute_input":"2023-03-23T05:26:16.494876Z","iopub.status.idle":"2023-03-23T05:26:16.544077Z","shell.execute_reply.started":"2023-03-23T05:26:16.494832Z","shell.execute_reply":"2023-03-23T05:26:16.543094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes=7)\ny_test = to_categorical(y_test, num_classes=7)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.545619Z","iopub.execute_input":"2023-03-23T05:26:16.546033Z","iopub.status.idle":"2023-03-23T05:26:16.552299Z","shell.execute_reply.started":"2023-03-23T05:26:16.545991Z","shell.execute_reply":"2023-03-23T05:26:16.551077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[0], y_train[-1]","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.554195Z","iopub.execute_input":"2023-03-23T05:26:16.555516Z","iopub.status.idle":"2023-03-23T05:26:16.564145Z","shell.execute_reply.started":"2023-03-23T05:26:16.555472Z","shell.execute_reply":"2023-03-23T05:26:16.562943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Creation","metadata":{}},{"cell_type":"code","source":"input_shape = (48, 48, 1)\noutput_class = 7","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.565790Z","iopub.execute_input":"2023-03-23T05:26:16.566235Z","iopub.status.idle":"2023-03-23T05:26:16.572473Z","shell.execute_reply.started":"2023-03-23T05:26:16.566186Z","shell.execute_reply":"2023-03-23T05:26:16.571252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# convolutional layers\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\n\n# fully connected layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\n\n# output layer\nmodel.add(Dense(7, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:16.574517Z","iopub.execute_input":"2023-03-23T05:26:16.575045Z","iopub.status.idle":"2023-03-23T05:26:18.294881Z","shell.execute_reply.started":"2023-03-23T05:26:16.575010Z","shell.execute_reply":"2023-03-23T05:26:18.293745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=3)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:18.296215Z","iopub.execute_input":"2023-03-23T05:26:18.296868Z","iopub.status.idle":"2023-03-23T05:26:18.305384Z","shell.execute_reply.started":"2023-03-23T05:26:18.296824Z","shell.execute_reply":"2023-03-23T05:26:18.304115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nhistory = model.fit(x = x_train, y = y_train, batch_size = 32, epochs = 100, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:26:18.307082Z","iopub.execute_input":"2023-03-23T05:26:18.308888Z","iopub.status.idle":"2023-03-23T05:43:31.384014Z","shell.execute_reply.started":"2023-03-23T05:26:18.308024Z","shell.execute_reply":"2023-03-23T05:43:31.382989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x = x_train, y = y_train, batch_size = 32, epochs = 20, validation_data=(x_test, y_test),callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2023-03-23T05:57:26.601531Z","iopub.execute_input":"2023-03-23T05:57:26.602265Z","iopub.status.idle":"2023-03-23T05:59:55.240990Z","shell.execute_reply.started":"2023-03-23T05:57:26.602228Z","shell.execute_reply":"2023-03-23T05:59:55.239893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict with test images","metadata":{}},{"cell_type":"code","source":"image_index = random.randint(0, len(test))\nprint(\"Original Output:\", test['label'][image_index])\npred = model.predict(x_test[image_index].reshape(1, 48, 48, 1))\nprediction_label = la.inverse_transform([pred.argmax()])[0]\nprint(\"Predicted Output:\", prediction_label)\nplt.imshow(x_test[image_index], cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-03-23T06:33:06.135417Z","iopub.execute_input":"2023-03-23T06:33:06.136113Z","iopub.status.idle":"2023-03-23T06:33:06.409133Z","shell.execute_reply.started":"2023-03-23T06:33:06.136077Z","shell.execute_reply":"2023-03-23T06:33:06.408143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_index = random.randint(0, len(test))\nprint(\"Original Output:\", test['label'][image_index])\npred = model.predict(x_test[image_index].reshape(1, 48, 48, 1))\nprediction_label = la.inverse_transform([pred.argmax()])[0]\nprint(\"Predicted Output:\", prediction_label)\nplt.subplots(figsize=(1, 1))\nplt.imshow(x_test[image_index], cmap='gray');\n","metadata":{"execution":{"iopub.status.busy":"2023-03-23T06:32:56.502083Z","iopub.execute_input":"2023-03-23T06:32:56.503079Z","iopub.status.idle":"2023-03-23T06:32:56.719180Z","shell.execute_reply.started":"2023-03-23T06:32:56.503026Z","shell.execute_reply":"2023-03-23T06:32:56.717889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_index = random.randint(0, len(test))\nprint(\"Original Output:\", test['label'][image_index])\npred = model.predict(x_test[image_index].reshape(1, 48, 48, 1))\nprediction_label = la.inverse_transform([pred.argmax()])[0]\nprint(\"Predicted Output:\", prediction_label)\nplt.subplots(figsize=(1,1))\nplt.imshow(x_test[image_index], cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-03-23T06:33:30.908925Z","iopub.execute_input":"2023-03-23T06:33:30.910144Z","iopub.status.idle":"2023-03-23T06:33:31.135871Z","shell.execute_reply.started":"2023-03-23T06:33:30.910098Z","shell.execute_reply":"2023-03-23T06:33:31.134306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_index = random.randint(0, len(test))\nprint(\"Original Output:\", test['label'][image_index])\npred = model.predict(x_test[image_index].reshape(1, 48, 48, 1))\nprediction_label = la.inverse_transform([pred.argmax()])[0]\nprint(\"Predicted Output:\", prediction_label)\nplt.subplots(figsize=(1,1))\nplt.imshow(x_test[image_index], cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-03-23T06:35:37.565361Z","iopub.execute_input":"2023-03-23T06:35:37.566171Z","iopub.status.idle":"2023-03-23T06:35:37.797039Z","shell.execute_reply.started":"2023-03-23T06:35:37.566128Z","shell.execute_reply":"2023-03-23T06:35:37.795785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}